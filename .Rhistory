clrhash()
clearPushBack()
library(readr)
ObesityDataSet <- read_csv("ObesityDataSet.csv")
View(ObesityDataSet)
library(readr)
table <- read_csv("table.csv")
View(table)
library(tidymodels)
library(xgboost)
library(vip)
library(skimr)
library(DT)
knitr::opts_chunk$set(echo=TRUE)
#Obesity <- read.csv('C:/Users/veron/Documents/Project_xgboost/ObesityDataSet.csv')
Obesity <- read.csv('ObesityDataSet.csv')
options(warn = -1)
head(Obesity)
# Features and values/categories
table <- read.csv("table.csv")
datatable(table)
skim_without_charts(Obesity)
non_numeric_columns <- Obesity[, !sapply(Obesity, is.numeric)]
non_numeric_columns
numeric_columns <- Obesity[, sapply(Obesity, is.numeric)]
numeric_columns
Obesity <- Obesity %>%
mutate(BMI = Weight / (Height * Height))
categories <- c("Underweight", "Normal", "Overweight", "Obesity_type_I", "Obesity_type_II", "Obesity_type_III")
limits_BMI <- c(0, 18.5, 24.9, 29.9, 34.9, 39.9, Inf)
BMI_class <- function(bmi) {
category <- cut(bmi, breaks = limits_BMI, labels = categories)
return(category)
}
Obesity <- Obesity %>%
mutate(BMI_category = BMI_class(BMI))
# Variable 'NObeyesdad' is eliminated
Obesity <- Obesity %>%
select(-NObeyesdad)
# Checking if the dataset has been modified
head(Obesity)
frec_ns <- Obesity %>%
count(BMI_category)
ggplot(frec_ns, aes(x = BMI_category, y = n)) +
geom_bar(stat = "identity", fill = "orange") +
labs(title = "Body Weight Category",
x = "Category",
y = "Frequency") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# I decided to remove the weight variable because the labels are calculated from it, I also removed BMI because it is used categorized.
Obesity <- Obesity %>%
select(-Weight, -BMI)
Obesity <- Obesity %>%
mutate(
FCVC = as.factor(FCVC),
NCP = as.factor(NCP),
TUE = as.factor(TUE),
CH2O = as.factor(CH2O),
FAF = as.factor(FAF)
)
set.seed(123)
o_split <- Obesity %>%
initial_split(prop = 0.75, strata = BMI_category)
o_train <- training(o_split)
o_test <- testing(o_split)
recipe_dt <- recipe(BMI_category~., data = o_train) %>%
step_corr(all_numeric_predictors()) %>% #elimino las correlaciones
step_center(all_numeric_predictors(), -all_outcomes()) %>% #centrado
step_scale(all_numeric_predictors(), -all_outcomes()) %>% #escalado
step_dummy(all_nominal_predictors())
prepared_recipe <- recipe_dt %>% prep()
prepared_recipe
# Model specifications
xgb_spec <- boost_tree(
trees = 1000,
tree_depth = tune(), min_n = tune(),
loss_reduction = tune(),                     ## first three: model complexity
sample_size = tune(), mtry = tune(),         ## randomness
learn_rate = tune()                          ## step size
) %>%
set_engine("xgboost") %>%
set_mode("classification")
xgb_spec
xgb_grid <- grid_latin_hypercube(
tree_depth(),
min_n(),
loss_reduction(),
sample_size = sample_prop(),
finalize(mtry(), o_train),
learn_rate(),
size = 10
)
xgb_grid
# Workflow creation
xgb_wf <- workflow() %>%
add_formula(BMI_category~.) %>%
add_model(xgb_spec)
xgb_wf
# Validation
o_folds <- vfold_cv(juice(prepared_recipe), strata = BMI_category)
doParallel::registerDoParallel()
set.seed(234)
xgb_res <- tune_grid(
xgb_wf,
resamples = o_folds,
grid = xgb_grid,
control = control_grid(save_pred = TRUE)
)
xgb_res
# Collect and summarize performance metrics for all hyperparameter combinations tested during the tuning process
collect_metrics(xgb_res)
xgb_res %>%
collect_metrics() %>%
filter(.metric == "roc_auc") %>%
select(mean, mtry:sample_size) %>%
pivot_longer(mtry:sample_size,
values_to = "value",
names_to = "parameter"
) %>%
ggplot(aes(value, mean, color = parameter)) +
geom_point(alpha = 0.8, show.legend = FALSE) +
facet_wrap(~parameter, scales = "free_x") +
labs(x = NULL, y = "AUC")
best_auc <- select_best(xgb_res, metric = "roc_auc")
show_best(xgb_res, metric = "roc_auc")
#The finalize_workflow() function is used to update a workflow with the best hyperparameter values
final_xgb <- finalize_workflow(
xgb_wf,
best_auc
)
final_xgb
final_xgb %>%
fit(juice(prepared_recipe)) %>%  #data extracted from the prepared_recipe object
pull_workflow_fit() %>%
vip(geom = "point")
# last_fit() emulates the process where, after determining the best model, the final fit on the entire training set is needed and is then evaluated on the test set
final_res <- last_fit(final_xgb, o_split)
collect_metrics(final_res)
# Prediction collection
predictions <- final_res %>%
collect_predictions()
# Confusion matrix
predictions %>%
conf_mat(BMI_category, .pred_class)
# Calculation of ROC curves for each class
roc_curve_data <- predictions %>%
roc_curve(truth = BMI_category,
.pred_Underweight,
.pred_Normal,
.pred_Overweight,
.pred_Obesity_type_I,
.pred_Obesity_type_II,
.pred_Obesity_type_III)
autoplot(roc_curve_data)
# Calculation of ROC curves for each class
roc_curve_data <- predictions %>%
roc_curve(truth = BMI_category,
.pred_Underweight,
.pred_Normal,
.pred_Overweight,
.pred_Obesity_type_I,
.pred_Obesity_type_II,
.pred_Obesity_type_III)
autoplot(roc_curve_data)
install.packages("jupytext")
library(jupitext)
install.packages("remotes")
remotes::install_github("mweber/jupytext")
unlink("~/project_xgboost/projxgb1_cache", recursive = TRUE)
knit_with_parameters("~/project_xgboost/projxgb1.Rmd")
version
library(jupitext)
install.packages("jupytext")
install.packages("jupytext")
library(jupitext)
install.packages("jupytext")
library(tidymodels)
library(xgboost)
library(vip)
library(skimr)
library(DT)
knitr::opts_chunk$set(echo=TRUE)
#Obesity <- read.csv('C:/Users/veron/Documents/Project_xgboost/ObesityDataSet.csv')
Obesity <- read.csv('ObesityDataSet.csv')
options(warn = -1)
head(Obesity)
# Features and values/categories
table <- read.csv("table.csv")
datatable(table)
skim_without_charts(Obesity)
non_numeric_columns <- Obesity[, !sapply(Obesity, is.numeric)]
non_numeric_columns
numeric_columns <- Obesity[, sapply(Obesity, is.numeric)]
numeric_columns
Obesity <- Obesity %>%
mutate(BMI = Weight / (Height * Height))
categories <- c("Underweight", "Normal", "Overweight", "Obesity_type_I", "Obesity_type_II", "Obesity_type_III")
limits_BMI <- c(0, 18.5, 24.9, 29.9, 34.9, 39.9, Inf)
BMI_class <- function(bmi) {
category <- cut(bmi, breaks = limits_BMI, labels = categories)
return(category)
}
Obesity <- Obesity %>%
mutate(BMI_category = BMI_class(BMI))
# Variable 'NObeyesdad' is eliminated
Obesity <- Obesity %>%
select(-NObeyesdad)
# Checking if the dataset has been modified
head(Obesity)
frec_ns <- Obesity %>%
count(BMI_category)
ggplot(frec_ns, aes(x = BMI_category, y = n)) +
geom_bar(stat = "identity", fill = "orange") +
labs(title = "Body Weight Category",
x = "Category",
y = "Frequency") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
install.packages("webshot2")
library(tidymodels)
library(xgboost)
library(vip)
library(skimr)
library(DT)
knitr::opts_chunk$set(  echo = TRUE,  screenshot.force = TRUE)
non_numeric_columns <- Obesity[, !sapply(Obesity, is.numeric)]
numeric_columns <- Obesity[, sapply(Obesity, is.numeric)]
cat("Unique values Non numerical variables:\n")
lapply(non_numeric_columns, unique)
cat("\nUnique values numeric variables:\n")
lapply(numeric_columns, unique)
non_numeric_columns <- Obesity[, !sapply(Obesity, is.numeric)]
numeric_columns <- Obesity[, sapply(Obesity, is.numeric)]
cat("Unique values Non numerical variables:\n")
lapply(non_numeric_columns, unique)
View(table)
load("C:/Users/veron/Downloads/table (2).csv")
# Features and values/categories
table <- read.csv("table (2).csv")
datatable(table)
non_numeric_columns <- Obesity[, !sapply(Obesity, is.numeric)]
numeric_columns <- Obesity[, sapply(Obesity, is.numeric)]
cat("Unique values Non numerical variables:\n")
lapply(non_numeric_columns, unique)
lapply(numeric_columns, summary())
non_numeric_columns <- Obesity[, !sapply(Obesity, is.numeric)]
numeric_columns <- Obesity[, sapply(Obesity, is.numeric)]
cat("Unique values Non numerical variables:\n")
lapply(non_numeric_columns, unique)
lapply(numeric_columns, summary)
